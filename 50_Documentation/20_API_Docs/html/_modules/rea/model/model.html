<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>rea.model.model &mdash; REA 2022 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->

        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
</head>

<body class="wy-body-for-nav">
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> REA
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <!-- Local TOC -->
              <div class="local-toc"></div>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">REA</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>rea.model.model</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">

  <h1>Source code for rea.model.model</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">Input</span>
<span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">MaxPool2D</span>
<span class="kn">from</span> <span class="nn">keras.optimizer_v2.adam</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">keras.optimizer_v2.learning_rate_schedule</span> <span class="kn">import</span> <span class="n">ExponentialDecay</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">from</span> <span class="nn">rea.data.data</span> <span class="kn">import</span> <span class="n">Data</span>
<span class="kn">from</span> <span class="nn">..processing_module</span> <span class="kn">import</span> <span class="n">ProcessingModule</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="n">ShapeType</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span>


<div class="viewcode-block" id="Model"><a class="viewcode-back" href="../../../rea.model.html#rea.model.model.Model">[docs]</a><span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">ProcessingModule</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Module for creating and training feed forward and convolutional</span>
<span class="sd">    neural networks.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Model.__init__"><a class="viewcode-back" href="../../../rea.model.html#rea.model.model.Model.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">output_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
            <span class="n">data_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
            <span class="n">nwtype</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
            <span class="n">hidden_layer_units</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
            <span class="n">hidden_layer_activations</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
            <span class="n">conv_layer_kernels</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
            <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
            <span class="n">use_class_weights</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">val_split</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
            <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>
            <span class="n">use_decay</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train an artificial neural network model for a fixed number of epochs.</span>

<span class="sd">        :param output_path: path where to save the model</span>
<span class="sd">        :param data_path: path to the `Data` output folder</span>
<span class="sd">        :param nwtype: The type of network to use (&quot;ff&quot; or &quot;conv&quot;)</span>
<span class="sd">        :param hidden_layer_units: the number of units for each hidden layer</span>
<span class="sd">        :param batch_size: number of samples per gradient update</span>
<span class="sd">        :param epochs: number of epochs to train the model</span>
<span class="sd">        :param use_class_weights: flag that enables or disables precomputed</span>
<span class="sd">         class_weights</span>
<span class="sd">         :param dropout: Rate for keras `Dropout` layer</span>
<span class="sd">        :param learning_rate: Learning rate for adam optimizer or</span>
<span class="sd">            initial learning rate for exponential decay</span>
<span class="sd">        :param use_decay: Use adam with exponential decay</span>
<span class="sd">        :param seed: random seed for numpy and tensorflow</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="n">data_path</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> <span class="n">nwtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_units</span> <span class="o">=</span> <span class="n">hidden_layer_units</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_activations</span> <span class="o">=</span> <span class="n">hidden_layer_activations</span>
        <span class="k">if</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;conv&quot;</span> <span class="ow">and</span> <span class="n">conv_layer_kernels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Type of network is conv, but &quot;</span>
                             <span class="s2">&quot;conv_layer_kernels are not provided.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_layer_kernels</span> <span class="o">=</span> <span class="n">conv_layer_kernels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="n">epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_class_weights</span> <span class="o">=</span> <span class="n">use_class_weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_split</span> <span class="o">=</span> <span class="n">val_split</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_decay</span> <span class="o">=</span> <span class="n">use_decay</span></div>

<div class="viewcode-block" id="Model.compile_model"><a class="viewcode-back" href="../../../rea.model.html#rea.model.model.Model.compile_model">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">compile_model</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>
                      <span class="n">learning_decay</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Configures the model for training</span>

<span class="sd">        :param model: The tensorflow model to compile</span>
<span class="sd">        :param learning_rate: Learning rate for adam optimizer or</span>
<span class="sd">            initial learning rate for exponential decay</span>
<span class="sd">        :param learning_decay: Use adam with exponential decay</span>

<span class="sd">        :return: compiled model</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">opt</span><span class="p">:</span> <span class="n">Adam</span>
        <span class="k">if</span> <span class="n">learning_decay</span><span class="p">:</span>
            <span class="c1"># use adam with exponential decay</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="n">ExponentialDecay</span><span class="p">(</span>
                <span class="n">initial_learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
                <span class="n">decay_rate</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span>
                <span class="n">decay_steps</span><span class="o">=</span><span class="mi">50</span>
            <span class="p">)</span>
            <span class="n">opt</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># use constant learning rate</span>
            <span class="n">opt</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">,</span>
                      <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">model</span></div>

<div class="viewcode-block" id="Model.create_ff_model"><a class="viewcode-back" href="../../../rea.model.html#rea.model.model.Model.create_ff_model">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">create_ff_model</span><span class="p">(</span><span class="n">input_shape</span><span class="p">:</span> <span class="n">ShapeType</span><span class="p">,</span> <span class="n">output_units</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                        <span class="n">units_per_layer</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
                        <span class="n">hidden_layer_activations</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
                        <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
                        <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>
                        <span class="n">use_decay</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a feed-forward style neural network with the specified number of</span>
<span class="sd">        hidden layers and activations.</span>

<span class="sd">        :param input_shape: the shape of the input data</span>
<span class="sd">        :param output_units: the number of output units (e.g. classes)</span>
<span class="sd">        :param units_per_layer: number of hidden units for each hidden layer</span>
<span class="sd">        :param hidden_layer_activations: name of activation function for each</span>
<span class="sd">            hidden layer</span>
<span class="sd">        :param dropout: Rate for keras `Dropout` layer</span>
<span class="sd">        :param learning_rate: Learning rate for adam optimizer or</span>
<span class="sd">            initial learning rate for exponential decay</span>
<span class="sd">        :param use_decay: Use adam with exponential decay</span>

<span class="sd">        :return: A keras Model with a feed-forward structure.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># create input layer</span>
        <span class="n">input_layer</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">input_shape</span><span class="p">))</span>
        <span class="c1"># add hidden layers</span>
        <span class="n">current_layer</span> <span class="o">=</span> <span class="n">input_layer</span>
        <span class="c1"># add dense (fully connected) layers in between according to parameters</span>
        <span class="k">for</span> <span class="n">n_units</span><span class="p">,</span> <span class="n">act</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">units_per_layer</span><span class="p">,</span> <span class="n">hidden_layer_activations</span><span class="p">):</span>
            <span class="n">current_layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">n_units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">act</span><span class="p">)(</span><span class="n">current_layer</span><span class="p">)</span>
        <span class="c1"># add dropout to prevent overfitting</span>
        <span class="n">drop</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)(</span><span class="n">current_layer</span><span class="p">)</span>
        <span class="c1"># add output layer</span>
        <span class="n">output_layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">output_units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)(</span><span class="n">drop</span><span class="p">)</span>
        <span class="c1"># assemble and compile model</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">output_layer</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Model</span><span class="o">.</span><span class="n">compile_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span>
                                   <span class="n">learning_decay</span><span class="o">=</span><span class="n">use_decay</span><span class="p">)</span></div>

<div class="viewcode-block" id="Model.create_conv_model"><a class="viewcode-back" href="../../../rea.model.html#rea.model.model.Model.create_conv_model">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">create_conv_model</span><span class="p">(</span><span class="n">input_shape</span><span class="p">:</span> <span class="n">ShapeType</span><span class="p">,</span>
                          <span class="n">output_units</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                          <span class="n">convolutions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
                          <span class="n">hidden_layer_activations</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
                          <span class="n">conv_layer_kernels</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
                          <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
                          <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>
                          <span class="n">use_decay</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
                          <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a convolutional network with the specified convolutions and</span>
<span class="sd">        input shape.</span>

<span class="sd">        :param input_shape: The shape of the input</span>
<span class="sd">        :param output_units: The number of output units (e.g. classes)</span>
<span class="sd">        :param convolutions: The number of convolutions for each hidden layer</span>
<span class="sd">        :param hidden_layer_activations: Activation functions for each hidden</span>
<span class="sd">            layer</span>
<span class="sd">        :param conv_layer_kernels: Kernel-size for each convolutional layer</span>
<span class="sd">        :param dropout: Rate for keras `Dropout` layer</span>
<span class="sd">        :param learning_rate: Learning rate for adam optimizer or</span>
<span class="sd">            initial learning rate for exponential decay</span>
<span class="sd">        :param use_decay: Use adam with exponential decay</span>

<span class="sd">        :return: A keras Model with a convolutional structure.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># create the input layer of the specified shape</span>
        <span class="n">inp</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">input_shape</span><span class="p">))</span>
        <span class="n">h_curr</span><span class="p">,</span> <span class="n">h_prev</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
        <span class="c1"># create convolutional layers according to parameters</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">conv</span><span class="p">,</span> <span class="n">act</span><span class="p">,</span> <span class="n">kernel</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="nb">zip</span><span class="p">(</span><span class="n">convolutions</span><span class="p">,</span> <span class="n">hidden_layer_activations</span><span class="p">,</span> <span class="n">conv_layer_kernels</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="n">h_curr</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">conv</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="n">kernel</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="n">act</span><span class="p">)</span>
            <span class="c1"># connect the first convolution to the input</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">h_curr</span> <span class="o">=</span> <span class="n">h_curr</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">h_curr</span> <span class="o">=</span> <span class="n">h_curr</span><span class="p">(</span><span class="n">MaxPool2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">h_prev</span><span class="p">))</span>
            <span class="n">h_prev</span> <span class="o">=</span> <span class="n">h_curr</span>
        <span class="c1"># create Flatten layer to map multidimensional filters to the flat</span>
        <span class="c1"># output layer</span>
        <span class="n">flat</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">MaxPool2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">h_curr</span><span class="p">))</span>
        <span class="c1"># add dropout to prevent overfitting</span>
        <span class="n">drop</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)(</span><span class="n">flat</span><span class="p">)</span>
        <span class="c1"># create a dense output layer mapping the flattened inputs to classes</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">output_units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)(</span><span class="n">drop</span><span class="p">)</span>
        <span class="c1"># build and compile the model</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inp</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Model</span><span class="o">.</span><span class="n">compile_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span>
                                   <span class="n">learning_decay</span><span class="o">=</span><span class="n">use_decay</span><span class="p">)</span></div>

<div class="viewcode-block" id="Model.run"><a class="viewcode-back" href="../../../rea.model.html#rea.model.model.Model.run">[docs]</a>    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Data</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Execute the primary module function.</span>

<span class="sd">        :param data: (Optional) Can be provided when using the API mode.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">input_units</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">num_features</span><span class="p">,)</span>
        <span class="n">output_units</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">num_classes</span>

        <span class="c1"># use different model construction based on the type</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;ff&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">original_shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot train ff model with input shape &gt; 2.&quot;</span><span class="p">)</span>
            <span class="n">model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_ff_model</span><span class="p">(</span>
                <span class="n">input_units</span><span class="p">,</span>
                <span class="n">output_units</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_units</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_activations</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">use_decay</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;conv&quot;</span><span class="p">:</span>
            <span class="n">model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_conv_model</span><span class="p">(</span>
                <span class="c1"># start at 1, because first dimension is always -1 for reshape</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">original_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span>
                <span class="n">output_units</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_units</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_activations</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">conv_layer_kernels</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">use_decay</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported model type &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">type</span><span class="si">}</span><span class="s2">&#39;.&quot;</span><span class="p">)</span>

        <span class="n">class_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">class_weights</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_class_weights</span><span class="p">:</span>
            <span class="n">class_weights</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">model_checkpoint_callback</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span>
            <span class="n">filepath</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span>
            <span class="n">save_weights_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_accuracy&quot;</span><span class="p">,</span>
            <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span>
            <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>

        <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">x_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">original_shape</span><span class="p">),</span>
            <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">y_train</span><span class="p">,</span>
            <span class="n">class_weight</span><span class="o">=</span><span class="n">class_weights</span><span class="p">,</span>
            <span class="n">epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">validation_split</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">val_split</span><span class="p">,</span>
            <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint_callback</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="c1"># model.save(self.output_dir)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model saved to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># plot training history</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax_loss</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
        <span class="n">ax_loss</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">)</span>
        <span class="n">ax_loss</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;val loss&quot;</span><span class="p">,</span>
                     <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:orange&quot;</span><span class="p">)</span>
        <span class="n">ax_loss</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Training History&quot;</span><span class="p">)</span>
        <span class="n">ax_loss</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">)</span>
        <span class="n">ax_loss</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">)</span>
        <span class="n">ax_acc</span> <span class="o">=</span> <span class="n">ax_loss</span><span class="o">.</span><span class="n">twinx</span><span class="p">()</span>
        <span class="n">ax_acc</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span>
                    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:green&quot;</span><span class="p">)</span>
        <span class="n">ax_acc</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_accuracy&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;val accuracy&quot;</span><span class="p">,</span>
                    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:red&quot;</span><span class="p">)</span>
        <span class="n">ax_acc</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
        <span class="n">ax_acc</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">)</span>
        <span class="n">ax_acc</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">)</span>
        <span class="n">ax_loss</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper left&quot;</span><span class="p">)</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="s2">&quot;history.png&quot;</span><span class="p">))</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Tom Kr√ºger, Lukas Zech, Erik Endlicher, Justin Kreikemeyer.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

</body>
</html>
